{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tournament.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl7Y3ogvVPVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e04e1232-c52e-4064-fafa-e9ed04bb2027"
      },
      "source": [
        "# !cp ./drive/MyDrive/Desktop.zip .\n",
        "# !unzip Desktop.zip\n",
        "import pickle\n",
        "\n",
        "# !cp ./drive/MyDrive/xy.pkl .\n",
        "with open('xy.pkl','rb') as file:\n",
        "  X,yr = pickle.load(file)\n",
        "\n",
        "!ls -ltrh"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1.2G\n",
            "drwxr-xr-x 1 root root 4.0K Jul 16 13:20 sample_data\n",
            "drwx------ 5 root root 4.0K Jul 25 14:09 drive\n",
            "-rw------- 1 root root 1.2G Jul 25 14:55 xy.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzyCuHElkjtR"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import *\n",
        "\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error,mean_squared_error,accuracy_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import *\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)\n",
        "from sklearn.tree import *\n",
        "# training_data = pd.read_csv(\"training_data.csv\").set_index('id')\n",
        "# # # #tournament_data = pd . read_csv ( 'tournament_data.csv' ) .set_index ('id')\n",
        "# X,y = training_data [ feature_names ] , training_data['target']\n",
        "# Xt = tournament_data [ feature_names]\n",
        "# with open('xy.pkl','wb') as file:\n",
        "#   pickle.dump([X,y],file)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmm0c8jHnYrS"
      },
      "source": [
        "def performance(mdlr,mdlc, X,yr,yc):\n",
        "  pr = mdlr.predict(X)\n",
        "  pc = mdlc.predict(X)\n",
        "  pc = le.inverse_transform(pc)\n",
        "  ar = mean_absolute_error(yr,pr)\n",
        "  ac = mean_absolute_error(yr,pc)\n",
        "  return ar, ac\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def rounder(values):\n",
        "    def f(x):\n",
        "        idx = np.argmin(np.abs(values - x))\n",
        "        return values[idx]\n",
        "    return np.frompyfunc(f, 1, 1)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8sC6YSQmdBg"
      },
      "source": [
        "feature_names = [f for f in X.columns if \"feature\" in f]\n",
        "\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(yr)\n",
        "yc = le.transform(yr)\n",
        "\n",
        "from sklearn.utils import resample\n",
        "X, yr, yc = resample(X, yr, yc,replace=False, n_samples=20000,random_state=0)\n",
        "X\n",
        "\n",
        "\n",
        "X_train, X_test, yr_train, yr_test, yc_train, yc_test = train_test_split(X, yr, yc, test_size=0.25, random_state=42, stratify=yr)\n",
        "\n",
        "\n",
        "min_class = yr.value_counts().min()\n",
        "\n",
        "NewDataX = np.zeros((1,len(feature_names)))\n",
        "NewDataY = []\n",
        "for c in [0, .25,.5,.75, 1]:\n",
        "  indices = yr[yr==c].sample(min_class).index\n",
        "  rows = X[X.index.isin(indices)]\n",
        "  NewDataX = np.vstack((NewDataX,rows.to_numpy()))\n",
        "  NewDataY.extend([c]*min_class)\n",
        "\n",
        "NewDataX = NewDataX[1:]\n",
        "NewDataY = np.array(NewDataY)\n",
        "\n",
        "yc2 = le.transform(NewDataY)\n",
        "\n",
        "X_train2, X_test2, yr_train2, yr_test2, yc_train2, yc_test2 = train_test_split(NewDataX, NewDataY, yc2, test_size=0.3, random_state=42)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK1u4BlIFUOM",
        "outputId": "790b358b-c978-42f0-eb2b-1b170a142ba1"
      },
      "source": [
        "X_train.shape, yr_test.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15000, 310), (5000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cUjv9Icl7v6",
        "outputId": "66eb70cd-0175-4ab7-c15c-d3aa06510094"
      },
      "source": [
        "# kwargs = dict(max_depth =3 , learning_rate =0.01 ,n_estimators =2 , colsample_bytree=0.5)\n",
        "# model = XGBClassifier (**kwargs)\n",
        "# model.fit(X_train,yc_train)\n",
        "\n",
        "# model = XGBRegressor (**kwargs)\n",
        "# model.fit(X_train,yr_train)\n",
        "\n",
        "# kwargs = dict()\n",
        "# model = make_pipeline(SGDClassifier(class_weight='balanced',**kwargs))\n",
        "# model.fit(X_train,yc_train)\n",
        "\n",
        "# model = make_pipeline(SGDRegressor(**kwargs))\n",
        "# model.fit(X_train,yr_train)\n",
        "\n",
        "# model = make_pipeline(LogisticRegression(class_weight='balanced'))\n",
        "# model.fit(X_train,yc_train)\n",
        "\n",
        "# model = make_pipeline(LinearRegression())\n",
        "# model.fit(X_train,yr_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('linearregression',\n",
              "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
              "                                  normalize=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms3TTRMmkFd7",
        "outputId": "07f8a659-1dc5-4651-e0f8-2c77394cfcee"
      },
      "source": [
        "p = model.predict(X_test)\n",
        "p2 = rounder(np.array([0,.25,.5,.75,1]))(p)\n",
        "# p = le.inverse_transform(p)\n",
        "mean_absolute_error(yr_test,p), mean_absolute_error(yr_test,p2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.15431995571734253, 0.14954125880814972)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "dvs127mMoJrI",
        "outputId": "61a0f248-a2b5-4b52-ae3f-36e0656701df"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(confusion_matrix(yc_test, p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f30039279d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Zns8lJA-kslH",
        "outputId": "bc4599bf-6032-4d86-c88b-682c5b768038"
      },
      "source": [
        "pd.DataFrame(np.vstack((yr_test[:1000],p[:1000])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>960</th>\n",
              "      <th>961</th>\n",
              "      <th>962</th>\n",
              "      <th>963</th>\n",
              "      <th>964</th>\n",
              "      <th>965</th>\n",
              "      <th>966</th>\n",
              "      <th>967</th>\n",
              "      <th>968</th>\n",
              "      <th>969</th>\n",
              "      <th>970</th>\n",
              "      <th>971</th>\n",
              "      <th>972</th>\n",
              "      <th>973</th>\n",
              "      <th>974</th>\n",
              "      <th>975</th>\n",
              "      <th>976</th>\n",
              "      <th>977</th>\n",
              "      <th>978</th>\n",
              "      <th>979</th>\n",
              "      <th>980</th>\n",
              "      <th>981</th>\n",
              "      <th>982</th>\n",
              "      <th>983</th>\n",
              "      <th>984</th>\n",
              "      <th>985</th>\n",
              "      <th>986</th>\n",
              "      <th>987</th>\n",
              "      <th>988</th>\n",
              "      <th>989</th>\n",
              "      <th>990</th>\n",
              "      <th>991</th>\n",
              "      <th>992</th>\n",
              "      <th>993</th>\n",
              "      <th>994</th>\n",
              "      <th>995</th>\n",
              "      <th>996</th>\n",
              "      <th>997</th>\n",
              "      <th>998</th>\n",
              "      <th>999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.515058</td>\n",
              "      <td>0.513411</td>\n",
              "      <td>0.506113</td>\n",
              "      <td>0.493145</td>\n",
              "      <td>0.510937</td>\n",
              "      <td>0.496495</td>\n",
              "      <td>0.473514</td>\n",
              "      <td>0.492045</td>\n",
              "      <td>0.509556</td>\n",
              "      <td>0.459865</td>\n",
              "      <td>0.468593</td>\n",
              "      <td>0.502087</td>\n",
              "      <td>0.51842</td>\n",
              "      <td>0.496734</td>\n",
              "      <td>0.489862</td>\n",
              "      <td>0.509825</td>\n",
              "      <td>0.491943</td>\n",
              "      <td>0.49697</td>\n",
              "      <td>0.511674</td>\n",
              "      <td>0.493045</td>\n",
              "      <td>0.521284</td>\n",
              "      <td>0.491361</td>\n",
              "      <td>0.499322</td>\n",
              "      <td>0.47999</td>\n",
              "      <td>0.504875</td>\n",
              "      <td>0.50936</td>\n",
              "      <td>0.486623</td>\n",
              "      <td>0.497496</td>\n",
              "      <td>0.488696</td>\n",
              "      <td>0.507226</td>\n",
              "      <td>0.491524</td>\n",
              "      <td>0.509394</td>\n",
              "      <td>0.486764</td>\n",
              "      <td>0.508553</td>\n",
              "      <td>0.504616</td>\n",
              "      <td>0.521886</td>\n",
              "      <td>0.505662</td>\n",
              "      <td>0.503712</td>\n",
              "      <td>0.535578</td>\n",
              "      <td>0.497601</td>\n",
              "      <td>...</td>\n",
              "      <td>0.504142</td>\n",
              "      <td>0.492402</td>\n",
              "      <td>0.497023</td>\n",
              "      <td>0.48444</td>\n",
              "      <td>0.503559</td>\n",
              "      <td>0.493181</td>\n",
              "      <td>0.523044</td>\n",
              "      <td>0.499846</td>\n",
              "      <td>0.485402</td>\n",
              "      <td>0.476231</td>\n",
              "      <td>0.501507</td>\n",
              "      <td>0.481353</td>\n",
              "      <td>0.492864</td>\n",
              "      <td>0.519936</td>\n",
              "      <td>0.512847</td>\n",
              "      <td>0.487265</td>\n",
              "      <td>0.486995</td>\n",
              "      <td>0.498794</td>\n",
              "      <td>0.496695</td>\n",
              "      <td>0.48391</td>\n",
              "      <td>0.509789</td>\n",
              "      <td>0.489176</td>\n",
              "      <td>0.508235</td>\n",
              "      <td>0.480633</td>\n",
              "      <td>0.494701</td>\n",
              "      <td>0.492628</td>\n",
              "      <td>0.497718</td>\n",
              "      <td>0.502905</td>\n",
              "      <td>0.504327</td>\n",
              "      <td>0.507877</td>\n",
              "      <td>0.489078</td>\n",
              "      <td>0.522948</td>\n",
              "      <td>0.489858</td>\n",
              "      <td>0.485811</td>\n",
              "      <td>0.50824</td>\n",
              "      <td>0.508873</td>\n",
              "      <td>0.490483</td>\n",
              "      <td>0.517193</td>\n",
              "      <td>0.49082</td>\n",
              "      <td>0.495226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows Ã— 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       997      998       999\n",
              "0         0       0.5      0.75  ...      0.25      0.5      0.75\n",
              "1  0.515058  0.513411  0.506113  ...  0.517193  0.49082  0.495226\n",
              "2       0.5       0.5       0.5  ...       0.5      0.5       0.5\n",
              "\n",
              "[3 rows x 1000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rn1_z-8mpCi",
        "outputId": "5afa58f4-67d2-46dd-dbeb-65c4d643ce4d"
      },
      "source": [
        "sr,sc = modelr.score(X_test,yr_test),modelc.score(X_test,yc_test)\n",
        "ar, ac = performance(modelr,modelc,X_test, yr_test,yc_test)\n",
        "np.array([ar, ac, sr,sc]).round(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1496 , 1.54955, 0.00002, 0.5018 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joHS8ZJ-9ymZ"
      },
      "source": [
        "# y = yr.to_numpy()\n",
        "# c1 = yr_train==0.5\n",
        "# c1t = yr_test==0.5\n",
        "\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.neural_network import MLPClassifier\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# mdl = make_pipeline(RandomForestClassifier(n_estimators=10,max_depth=3))\n",
        "# mdl.fit(X_train, c1)\n",
        "# mdl.score(X_test, c1t),mdl.score(X_train, c1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlcGQfuztaa9",
        "outputId": "e78466e0-154e-4afd-f2c8-97fc8e98f97f"
      },
      "source": [
        "mdl = LinearRegression()\n",
        "mdl.fit(X_train2,yr_train2)\n",
        "y_pred = mdl.predict(X_test)\n",
        "y_pred2 = mdl.predict(X_test2)\n",
        "mean_absolute_error(yr_test, y_pred),mean_absolute_error(yr_test2, y_pred2), mdl.score(X_test2,yr_test2), mdl.score(X_test,yr_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.16091360621606018,\n",
              " 0.30212421652518995,\n",
              " 0.001296873902373652,\n",
              " -0.007303020088332391)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txJGYXLhtaYy",
        "outputId": "5066da19-6394-4273-c66a-9466fa56f220"
      },
      "source": [
        "mdl = LogisticRegression(max_iter=5000)\n",
        "mdl.fit(X_train2,yc_train2)\n",
        "y_pred = mdl.predict(X_test)\n",
        "y_pred = le.inverse_transform(y_pred)\n",
        "y_pred2 = mdl.predict(X_test2)\n",
        "y_pred2 = le.inverse_transform(y_pred2)\n",
        "mean_absolute_error(yr_test, y_pred),mean_absolute_error(yr_test2, y_pred2), mdl.score(X_test2,yc_test2), mdl.score(X_test,yc_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.5448727401715396,\n",
              " 1.683902302526383,\n",
              " 0.29258607824325766,\n",
              " 0.32971973344386696)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tST_rnoKtaP0",
        "outputId": "ca482b93-1e4c-42b1-b3a5-82125d367cee"
      },
      "source": [
        "mean_absolute_error(yr_test, y_pred),mean_absolute_error(yr_test2, y_pred2),"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.28276651627714183, 0.3686440677966102)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH0hjC4AA1WF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuuamrVnA1n0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACJ-NsgXA2HO",
        "outputId": "0bb7aba6-52df-45d8-8fa1-9c92a335b3fe"
      },
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "models = [\n",
        "          # KNeighborsRegressor(),\n",
        "          LinearRegression(), DecisionTreeRegressor(), MLPRegressor(3)]\n",
        "for model in models:\n",
        "  estimator = BaggingRegressor(model, max_samples=0.5, max_features=0.5,n_jobs=-1,random_state=0)\n",
        "  estimator.fit(X_train,yr_train)\n",
        "  pred = estimator.predict(X_test)\n",
        "  score = round(mean_absolute_error(yr_test, pred),4)\n",
        "  print('Bagging',model.__class__.__name__,score)\n",
        "\n",
        "from sklearn.ensemble import *\n",
        "\n",
        "estimator = RandomForestRegressor(n_estimators=10)\n",
        "estimator.fit(X_train,yr_train)\n",
        "pred = estimator.predict(X_test)\n",
        "score = round(mean_absolute_error(yr_test, pred),4)\n",
        "print('Forest',estimator.__class__.__name__,score)\n",
        "\n",
        "estimator = AdaBoostRegressor()\n",
        "estimator.fit(X_train,yr_train)\n",
        "pred = estimator.predict(X_test)\n",
        "score = round(mean_absolute_error(yr_test, pred),4)\n",
        "print('Boosting',estimator.__class__.__name__,score)\n",
        "\n",
        "\n",
        "reg1 = GradientBoostingRegressor(random_state=1)\n",
        "reg2 = RandomForestRegressor(random_state=1)\n",
        "reg3 = LinearRegression()\n",
        "\n",
        "ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
        "ereg = ereg.fit(X_train, yr_train)\n",
        "pred = ereg.predict(X_test)\n",
        "score = round(mean_absolute_error(yr_test, pred),4)\n",
        "print('Voting', score)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bagging LinearRegression 0.1581\n",
            "Bagging DecisionTreeRegressor 0.1784\n",
            "Bagging MLPRegressor 0.1537\n",
            "Forest RandomForestRegressor 0.1785\n",
            "Boosting AdaBoostRegressor 0.1543\n",
            "Voting 0.1573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfdzCblsClgT",
        "outputId": "dfc38f0f-fd43-4cd1-a624-f1874182c993"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvppNTuxNadz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}